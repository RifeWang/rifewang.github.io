<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Kubernetes - Tag - 凌虚 Blog</title><link>https://rifewang.github.io/tags/kubernetes/</link><description>Kubernetes - Tag - 凌虚 Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)</copyright><lastBuildDate>Thu, 26 Sep 2024 14:30:07 +0800</lastBuildDate><atom:link href="https://rifewang.github.io/tags/kubernetes/" rel="self" type="application/rss+xml"/><item><title>OCI 简介：Kubernetes 环境下从代码到容器的全流程</title><link>https://rifewang.github.io/oci/</link><pubDate>Thu, 26 Sep 2024 14:30:07 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/oci/</guid><description><![CDATA[<h2 id="oci-简介">OCI 简介</h2>
<p>在容器化技术的演进中，<code>OCI</code>（Open Container Initiative）提供了一套标准化的规范，帮助统一容器的构建、分发和运行。<code>OCI</code> 规范包含三个部分：</p>]]></description></item><item><title>kubectl 执行一条命令之后发生了什么？</title><link>https://rifewang.github.io/kubectl-to-k8s/</link><pubDate>Sun, 22 Sep 2024 14:34:08 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/kubectl-to-k8s/</guid><description><![CDATA[<p><code>kubectl</code> 是与 Kubernetes 集群交互的命令行工具，用户通过它可以对集群资源进行操作和管理。你有没有想过，当我们执行一条 <code>kubectl</code> 命令之后，背后都发生了什么？</p>
<h2 id="详细过程">详细过程</h2>
<h3 id="kubectl---kube-api-server">kubectl -&gt; kube-api-server</h3>
<p>根据通信类型，我把 <code>kubectl</code> 命令分为两类：单向通信和双向通信。</p>]]></description></item><item><title>Kubernetes 集群内 DNS</title><link>https://rifewang.github.io/k8s-dns/</link><pubDate>Tue, 17 Sep 2024 19:50:36 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/k8s-dns/</guid><description><![CDATA[<h2 id="dns-简介">DNS 简介</h2>
<p>在互联网早期，随着连接设备数量的增加，IP 地址的管理与记忆变得越来越复杂。为了简化网络资源的访问，<code>DNS</code>（Domain Name System）应运而生。<code>DNS</code> 的核心作用是将用户可读的域名（如 <a href="https://www.example.com" target="_blank" rel="noopener noreffer ">www.example.com</a>）解析为对应的 IP 地址（如 93.184.215.34），从而使用户无需记忆复杂的数字串，便能轻松访问全球各地的网络资源。</p>]]></description></item><item><title>Kubernetes CNI 网络模型概览：VETH &amp; Bridge / Overlay / BGP</title><link>https://rifewang.github.io/k8s-cni-network-model/</link><pubDate>Fri, 13 Sep 2024 12:11:23 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/k8s-cni-network-model/</guid><description><![CDATA[<h2 id="序言">序言</h2>
<p>网络是容器通信的基础，Kubernetes 本身并未提供开箱即用的网络互通功能，只提出了两点基本要求：</p>
<blockquote>
<ul>
<li>pods can communicate with all other pods on any other node without NAT</li>
<li>agents on a node (e.g. system daemons, kubelet) can communicate with all pods on that node</li>
</ul>
</blockquote>
<p>至于如何实现这些通信能力，通常依赖于 <code>CNI</code> 插件来完成。</p>]]></description></item><item><title>Kubernetes 之 kubelet 与 CRI、CNI 的交互过程</title><link>https://rifewang.github.io/kubelet-cri-cni/</link><pubDate>Sat, 07 Sep 2024 14:46:34 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/kubelet-cri-cni/</guid><description><![CDATA[<h2 id="序言">序言</h2>
<p>当一个新的 Pod 被提交创建之后，<code>Kubelet</code>、<code>CRI</code>、<code>CNI</code> 这三个组件之间进行了哪些交互？</p>
<h2 id="kubelet---cri---cni">Kubelet -&gt; CRI -&gt; CNI</h2>
<p></p>
<p>如上图所示：</p>
<ol>
<li><code>Kubelet</code> 从 kube-api-server 处监听到有新的 pod 被调度到了自己的节点且需要创建。</li>
<li><code>Kubelet</code> 创建 sandbox 并配置好 Pod 的环境，其中包括：
<ul>
<li><code>Kubelet</code> 通过 gRPC 调用 <code>CRI</code> 组件创建 sandbox。</li>
<li><code>CRI</code> 通过命令行调用 <code>CNI</code> 设置 pod 的网络。</li>
</ul>
</li>
<li><code>Kubelet</code> 创建 container 阶段：
<ul>
<li>调用 <code>CRI</code> 拉取镜像。</li>
<li>调用 <code>CRI</code> 创建 container。</li>
<li>调用 <code>CRI</code> 启动 container。</li>
</ul>
</li>
</ol>
<p>注意：</p>]]></description></item><item><title>Kubernetes 网关流量管理：Ingress 与 Gateway API</title><link>https://rifewang.github.io/k8s-ingress-vs-gateway/</link><pubDate>Sat, 31 Aug 2024 17:09:40 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/k8s-ingress-vs-gateway/</guid><description><![CDATA[<h2 id="引言">引言</h2>
<p>随着 Kubernetes 在云原生领域的广泛使用，流量管理成为了至关重要的一环。为了有效地管理从外部流入集群的流量，Kubernetes 提供了多种解决方案，其中最常见的是 <code>Ingress</code> 和新兴的 <code>Gateway API</code>。</p>]]></description></item><item><title>Kubernetes scheduler 概述及自定义调度器</title><link>https://rifewang.github.io/k8s-custom-scheduler/</link><pubDate>Sat, 15 Jun 2024 20:04:06 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/k8s-custom-scheduler/</guid><description><![CDATA[<h2 id="kube-scheduler">kube-scheduler</h2>
<p><code>kube-scheduler</code> 是 k8s 集群中控制平面的一个重要组件，其负责的工作简单且专一：给未分配的 pod 分配一个 node 节点。</p>
<p>调度器的大致工作过程可以分为以下几步：</p>
<ul>
<li>监听到未绑定 node 的 pod。</li>
<li>过滤节点：挑选出来适合分配这个 pod 的 node 节点（可能有多个）。</li>
<li>节点打分：给过滤出来的节点进行打分。</li>
<li>最后选择得分最高的那个 node 与 pod 绑定（如果最高得分有多个 node 则随机选择一个）。</li>
</ul>
<p>更加详细的步骤则参考下图所示：</p>]]></description></item><item><title>Kubernetes Service 与 long-lived connections</title><link>https://rifewang.github.io/k8s-service-long-lived-connection/</link><pubDate>Wed, 12 Jun 2024 16:14:46 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/k8s-service-long-lived-connection/</guid><description><![CDATA[<p>本文将会介绍：</p>
<ul>
<li>从 pod 到 service 再到 pod，kubernetes 中的流量是怎么走的？</li>
<li>对于 long-lived connection 长连接又是怎样的情况？</li>
</ul>
<h2 id="从-pod-到-service-再到-pod">从 pod 到 service 再到 pod</h2>
<p></p>
<p>如上图所示：</p>]]></description></item><item><title>我的 2024 年 CKA 认证两天速通攻略</title><link>https://rifewang.github.io/2024-cka-cert/</link><pubDate>Sat, 27 Jan 2024 23:23:16 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/2024-cka-cert/</guid><description><![CDATA[<h2 id="背景说明">背景说明</h2>
<p></p>
<p>如上图所示，本人于 2024 年 1 月 22 号晚上 11 点进行了 CKA 的认证考试，并以 95 分（满分100）顺利通过拿证。本文将会介绍我的 CKA 考试心得和速通攻略。</p>]]></description></item><item><title>Kubernetes 外部 HTTP 请求到达 Pod 容器的全过程</title><link>https://rifewang.github.io/http-flow-to-container/</link><pubDate>Sat, 30 Dec 2023 16:38:11 +0800</pubDate><author>凌虚</author><guid>https://rifewang.github.io/http-flow-to-container/</guid><description><![CDATA[<p><code>Kubernetes</code> 集群外部的 HTTP/HTTPS 请求是如何达到 Pod 中的 <code>container</code> 的？</p>
<h2 id="http-请求流转过程概述">HTTP 请求流转过程概述</h2>
<p></p>
<p>如上图所示，全过程大致为：</p>
<ol>
<li>用户从 web/mobile/pc 等客户端发出 HTTP/HTTPS 请求。</li>
<li>由于应用服务通常是通过域名的形式对外暴露，所以请求将会先进行 <code>DNS</code> 域名解析，得到对应的公网 <code>IP</code> 地址。</li>
<li>公网 <code>IP</code> 地址通常会绑定一个 <code>Load Balancer</code> 负载均衡器，此时请求会进入此负载均衡器。
<ul>
<li><code>Load Balancer</code> 负载均衡器可以是硬件，也可以是软件，它通常会保持稳定（固定的公网 IP 地址），因为如果切换 IP 地址会因为 DNS 缓存的原因导致服务某段时间内不可达。</li>
<li><code>Load Balancer</code> 负载均衡器是一个重要的中间层，对外承接公网流量，对内进行流量的管理和转发。</li>
</ul>
</li>
<li><code>Load Balancer</code> 再将请求转发到 <code>kubernetes</code> 集群的某个流量入口点，通常是 <code>ingress</code>。
<ul>
<li><code>ingress</code> 负责集群内部的路由转发，可以看成是集群内部的网关。</li>
<li><code>ingress</code> 只是配置，具体进行流量转发的是 <code>ingress-controller</code>，后者有多种选择，比如 Nginx、HAProxy、Traefik、Kong 等等。</li>
</ul>
</li>
<li><code>ingress</code> 根据用户自定义的路由规则进一步转发到 <code>service</code>。
<ul>
<li>比如根据请求的 path 路径或 host 做转发。

</li>
</ul>
</li>
<li><code>service</code> 根据 selector（匹配 label 标签）将请求转发到 <code>pod</code>。
<ul>
<li><code>service</code> 有多种类型，集群内部最常用的类型就是 <code>ClusterIP</code>。</li>
<li><code>service</code> 本质上也只是一种配置，这种配置最终会作用到 node 节点上的 <code>kube-proxy</code> 组件，后者会通过设置 <code>iptables/ipvs</code> 来完成实际的请求转发。</li>
<li><code>service</code> 可能会对应多个 <code>pod</code>，但最终请求只会被随机转发到一个 <code>pod</code> 上。</li>
</ul>
</li>
<li><code>pod</code> 最后将请求发送给其中的 <code>container</code> 容器。
<ul>
<li>同一个 <code>pod</code> 内部可能有多个 <code>container</code>，但是多个容器不能共用同一个端口，因此这里会根据具体的端口号将请求发给对应的 <code>container</code>。</li>
</ul>
</li>
</ol>
<p>以上就是一种典型的集群外部 HTTP 请求如何达到 Pod 中的 <code>container</code> 的全过程。</p>]]></description></item></channel></rss>