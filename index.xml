<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>凌虚 Blog</title><link>https://rifewang.github.io/</link><description>Recent content on 凌虚 Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 15 Apr 2022 00:00:00 +0800</lastBuildDate><atom:link href="https://rifewang.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>关于我</title><link>https://rifewang.github.io/about/</link><pubDate>Tue, 14 Feb 2023 17:03:10 +0800</pubDate><guid>https://rifewang.github.io/about/</guid><description> ⭐ I am RifeWang Link to heading 🧑‍💻 A back-end software developer and system architect. ❤️ Love node.js and go, good at elasticsearch and kubernetes. 🏠 Currently working and living in Hangzhou, China. 💬 You can communicate technical issues with me through my WeChat: rifewang . 🛠 My Tech Stack Link to heading 💻 🌐 🛢 🔧</description></item><item><title>Elasticsearch 向量搜索</title><link>https://rifewang.github.io/posts/elasticsearch/es-vector-search/</link><pubDate>Fri, 15 Apr 2022 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-vector-search/</guid><description>Elasticsearch 向量搜索 Link to heading 本文将会介绍 Elasticsearch 向量搜索的两种方式。
向量搜索 Link to heading 提到向量搜索，我想你一定想知道：
向量搜索是什么？ 向量搜索的应用场景有哪些？ 向量搜索与全文搜索有何不同？ ES 的全文搜索简而言之就是将文本进行分词，然后基于词通过 BM25 算法计算相关性得分，从而找到与搜索语句相似的文本，其本质上是一种 term-based（基于词）的搜索。
全文搜索的实际使用已经非常广泛，核心技术也非常成熟。但是，除了文本内容之外，现实生活中还有非常多其它的数据形式，例如：图片、音频、视频等等，我们能不能也对这些数据进行搜索呢？
答案是 Yes !
随着机器学习和人工智能等技术的发展，万物皆可 Embedding。换句话说就是，我们可以对文本、图片、音频、视频等等一切数据通过 Embedding 相关技术将其转换成特征向量，而一旦向量有了，向量搜索的需求随之也越发强烈，向量搜索的应用场景也变得一望无际、充满想象力。
ES 向量搜索说明 Link to heading ES 向量搜索目前有两种方式:
script_score _knn_search script_score 精确搜索 Link to heading ES 7.6 版本对新增的字段类型 dense_vector 确认了稳定性保证，这个字段类型就是用来表示向量数据的。
数据建模示例：
PUT my-index { &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;my_vector&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;dense_vector&amp;#34;, &amp;#34;dims&amp;#34;: 128 }, &amp;#34;my_text&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;keyword&amp;#34; } } } } 如上图所示，我们在索引中建立了一个 dims 维度为 128 的向量数据字段。</description></item><item><title>Terraform: 基础设施即代码</title><link>https://rifewang.github.io/posts/devops/terraform-overview/</link><pubDate>Sun, 27 Mar 2022 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/devops/terraform-overview/</guid><description>Terraform: 基础设施即代码 Link to heading 问题 Link to heading 现如今有很多 IT 系统的基础设施直接使用了云厂商提供的服务，假设我们需要构建以下基础设施：
VPC 网络 虚拟主机 负载均衡器 数据库 文件存储 &amp;hellip; 那么在公有云的环境中，我们一般怎么做？
在云厂商提供的前端管理页面上手动操作吗？
这也太费劲了吧，尤其是当基础设施越来越多、越来越复杂、以及跨多个云环境的时候，这些基础设施的配置和管理便会碰到一个巨大的挑战。
Terraform Link to heading 为了解决上述问题，Terrafrom 应运而生。
使用 Terraform ，我们只需要编写简单的声明式代码，形如：
... resource &amp;#34;alicloud_db_instance&amp;#34; &amp;#34;instance&amp;#34; { engine = &amp;#34;MySQL&amp;#34; engine_version = &amp;#34;5.6&amp;#34; instance_type = &amp;#34;rds.mysql.s1.small&amp;#34; instance_storage = &amp;#34;10&amp;#34; ... } 然后执行几个简单的 terraform 命令便可以轻松创建一个阿里云的数据库实例。
这就是 Infrastructure as code 基础设施即代码。也就是通过代码而不是手动流程来管理和配置基础设施。
正如其官方文档所述，与手动管理基础设施相比，使用 Terraform 有以下几个优势：
Terraform 可以轻松管理多个云平台上的基础设施。 使用人类可读的声明式的配置语言，有助于快速编写基础设施代码。 Terraform 的状态允许您在整个部署过程中跟踪资源更改。 可以对这些基础设施代码进行版本控制，从而安全地进行协作。 Provider &amp;amp; Module Link to heading 你也许会感到困惑，我只是简单的应用了所写的声明式代码，怎么就构建出来了基础设施，这中间发生了什么？</description></item><item><title>加速 Kubernetes 镜像拉取</title><link>https://rifewang.github.io/posts/kubernetes/speed-up-image-pull/</link><pubDate>Sun, 13 Mar 2022 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/kubernetes/speed-up-image-pull/</guid><description>加速 Kubernetes 镜像拉取 Link to heading Kubernetes pod 启动时会拉取用户指定的镜像，一旦这个过程耗时太久就会导致 pod 长时间处于 pending 的状态，从而无法快速提供服务。
镜像拉取的过程参考下图所示：
Pod 的 imagePullPolicy 镜像拉取策略有三种：
IfNotPresent：只有当镜像在本地不存在时才会拉取。 Always：kubelet 会对比镜像的 digest ，如果本地已缓存则直接使用本地缓存，否则从镜像仓库中拉取。 Never：只使用本地镜像，如果不存在则直接失败。 说明：每个镜像的 digest 一定唯一，但是 tag 可以被覆盖。
从镜像拉取的过程来看，我们可以从以下三个方面来加速镜像拉取：
缩减镜像大小： 使用较小的基础镜像、移除无用的依赖、减少镜像 layer 、使用多阶段构建等等。 推荐使用 docker-slim 加快镜像仓库与 k8s 节点之间的网络传输速度。 主动缓存镜像： Pre-pulled 预拉取镜像，以便后续直接使用本地缓存，比如可以使用 daemonset 定期同步仓库中的镜像到 k8s 节点本地。 题外话 1：本地镜像缓存多久？是否会造成磁盘占用问题？
本地缓存的镜像一定会占用节点的磁盘空间，也就是说缓存的镜像越多，占用的磁盘空间越大，并且缓存的镜像默认一直存在，并没有 TTL 机制（比如说多长时间以后自动过期删除）。
但是，k8s 的 GC 机制会自动清理掉镜像。当节点的磁盘使用率达到 HighThresholdPercent 高百分比阈值时（默认 85% ）会触发垃圾回收，此时 kubelet 会根据使用情况删除最旧的不再使用的镜像，直到磁盘使用率达到 LowThresholdPercent（默认 80% ）。
题外话 2：镜像 layer 层数真的越少越好吗？
我们经常会看到一些文章说在 Dockerfile 里使用更少的 RUN 命令之类的减少镜像的 layer 层数然后缩减镜像的大小，layer 越少镜像越小这确实没错，但是某些场景下得不偿失。首先，如果你的 RUN 命令很大，一旦你修改了其中某一个小的部分，那么这个 layer 在构建的时候就只能重新再来，无法使用任何缓存；其次，镜像的 layer 在上传和下载的过程中是可以并发的，而单独一个大的层无法进行并发传输。</description></item><item><title>解读 MySQL Client/Server Protocol: Connection &amp; Replication</title><link>https://rifewang.github.io/posts/mysql/protocol-connectionreplication/</link><pubDate>Sun, 20 Dec 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/mysql/protocol-connectionreplication/</guid><description>解读 MySQL Client/Server Protocol: Connection &amp;amp; Replication Link to heading MySQL 客户端与服务器之间的通信基于特定的 TCP 协议，本文将会详解其中的 Connection 和 Replication 部分，这两个部分分别对应的是客户端与服务器建立连接、完成认证鉴权，以及客户端注册成为一个 slave 并获取 master 的 binlog 日志。
Connetcion Phase Link to heading MySQL 客户端想要与服务器进行通信，第一步就是需要成功建立连接，整个过程如下图所示：
client 发起一个 TCP 连接。 server 响应一个 Initial Handshake Packet（初始化握手包），内容会包含一个默认的认证方式。 这一步是可选的，双方建立 SSL 加密连接。 client 回应 Handshake Response Packet，内容需要包括用户名和按照指定方式进行加密后的密码数据。 server 响应 OK_Packet 确认认证成功，或者 ERR_Packet 表示认证失败并关闭连接。 Packet Link to heading 一个 Packet 其实就是一个 TCP 包，所有包都有一个最基本的结构：
如上图所示，所有包都可以看作由 header 和 body 两部分构成：第一部分 header 总共有 4 个字节，3 个字节用来标识 body 即 payload 的大小，1 个字节记录 sequence ID；第二部分 body 就是 payload 实际的负载数据。</description></item><item><title>同步 MySQL 数据至 Elasticsearch/Redis/MQ 等的五种方式</title><link>https://rifewang.github.io/posts/mysql/sync-data-from-mysql/</link><pubDate>Mon, 30 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/mysql/sync-data-from-mysql/</guid><description>同步 MySQL 数据至 Elasticsearch/Redis/MQ 等的五种方式 Link to heading 在实际应用中，我们经常需要把 MySQL 的数据同步至其它数据源，也就是在对 MySQL 的数据进行了新增、修改、删除等操作后，把该数据相关的业务逻辑变更也应用到其它数据源，例如：
MySQL -&amp;gt; Elasticsearch ，同步 ES 的索引 MySQL -&amp;gt; Redis ，刷新缓存 MySQL -&amp;gt; MQ (如 Kafka 等) ，投递消息 本文总结了五种数据同步的方式。
1. 业务层同步 Link to heading 由于对 MySQL 数据的操作也是在业务层完成的，所以在业务层同步操作另外的数据源也是很自然的，比较常见的做法就是在 ORM 的 hooks 钩子里编写相关同步代码。
这种方式的缺点是，当服务越来越多时，同步的部分可能会过于分散从而导致难以更新迭代，例如对 ES 索引进行不兼容迁移时就可能会牵一发而动全身。
2. 中间件同步 Link to heading 当应用架构演变为微服务时，各个服务里可能不再直接调用 MySQL ，而是通过一层 middleware 中间件，这时候就可以在中间件操作 MySQL 的同时同步其它数据源。
这种方式需要中间件去适配，具有一定复杂度。
3. 定时任务根据 updated_at 字段同步 Link to heading 在 MySQL 的表结构里设置特殊的字段，如 updated_at（数据的更新时间），根据此字段，由定时任务去查询实际变更的数据，从而实现数据的增量更新。</description></item><item><title>Elasticsearch 分布式搜索的运行机制</title><link>https://rifewang.github.io/posts/elasticsearch/es-distribute-search-steps/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-distribute-search-steps/</guid><description>Elasticsearch 分布式搜索的运行机制 Link to heading ES 有两种 search_type 即搜索类型：
query_then_fetch （默认） dfs_query_then_fetch query_then_fetch Link to heading 用户发起搜索，请求到集群中的某个节点。 query 会被发送到所有相关的 shard 分片上。 每个 shard 分片独立执行 query 搜索文档并进行排序分页等，打分时使用的是分片本身的 Local Term/Document 频率。 分片的 query 结果（只有元数据，例如 _id 和 _score）返回给请求节点。 请求节点对所有分片的 query 结果进行汇总，然后根据打分排序和分页，最后选择出搜索结果文档（也只有元数据）。 根据元数据去对应的 shard 分片拉取存储在磁盘上的文档的详细数据。 得到详细的文档数据，组成搜索结果，将结果返回给用户。 缺点：由于每个分片独立使用自身的而不是全局的 Term/Document 频率进行相关度打分，当数据分布不均匀时可能会造成打分偏差，从而影响最终搜索结果的相关性。
dfs_query_then_fetch Link to heading dfs_query_then_fetch 与 query_then_fetch 的运行机制非常类似，但是有两点不同。
用户发起搜索，请求到集群中的某个节点。 预查询每个分片，得到全局的 Global Term/Document 频率。 query 会被发送到所有相关的 shard 分片上。 每个 shard 分片独立执行 query 搜索文档并进行排序分页等，打分时使用的是分片本身的 Global Term/Document 频率。 分片的 query 结果（只有元数据，例如 _id 和 _score）返回给请求节点。 请求节点对所有分片的 query 结果进行汇总，然后根据打分排序和分页，最后选择出搜索结果文档（也只有元数据）。 根据元数据去对应的 shard 分片拉取存储在磁盘上的文档的详细数据。 得到详细的文档数据，组成搜索结果，将结果返回给用户。 缺点：太耗费资源，一般还是不建议使用。</description></item><item><title>Elasticsearch Search Template</title><link>https://rifewang.github.io/posts/elasticsearch/es-search-template/</link><pubDate>Mon, 16 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-search-template/</guid><description>Elasticsearch Search Template Link to heading 所谓 search template 搜索模板其实就是：
预先定义好查询语句 DSL 的结构并预留参数 搜索的时再传入参数值 渲染出完整的 DSL ，最后进行搜索 使用搜索模板可以将 DSL 从应用程序中解耦出来，并且可以更加灵活的更改查询语句。
例如：
GET _search/template { &amp;#34;source&amp;#34; : { &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34; : { &amp;#34;{{my_field}}&amp;#34; : &amp;#34;{{my_value}}&amp;#34; } } }, &amp;#34;params&amp;#34; : { &amp;#34;my_field&amp;#34; : &amp;#34;message&amp;#34;, &amp;#34;my_value&amp;#34; : &amp;#34;foo&amp;#34; } } 构造出来的 DSL 就是：
{ &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34;: { &amp;#34;message&amp;#34;: &amp;#34;foo&amp;#34; } } } 在模板中通过 {{ }} 的方式预留参数，然后查询时再指定对应的参数值，最后填充成具体的查询语句进行搜索。
搜索模板 API Link to heading 为了实现搜索模板和查询分离，我们首先需要单独保存和管理搜索模板。</description></item><item><title>构造请求日志分析系统</title><link>https://rifewang.github.io/posts/elasticsearch/log-analyzer-system/</link><pubDate>Sat, 07 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/log-analyzer-system/</guid><description>构造请求日志分析系统 Link to heading 请求日志记录哪些数据 Link to heading time_local : 请求的时间 remote_addr : 客户端的 IP 地址 request_method : 请求方法 request_schema : 请求协议，常见的 http 和 https request_host : 请求的域名 request_path : 请求的 path 路径 request_query : 请求的 query 参数 request_size : 请求的大小 referer : 请求来源地址，假设你在 a.com 网站下贴了 b.com 的链接，那么当用户从 a.com 点击访问 b.com 的时候，referer 记录的就是 a.com ，这个是浏览器的行为 user_agent : 客户端浏览器相关信息 status : 请求的响应状态 request_time : 请求的耗时 bytes_sent : 响应的大小 很多时候我们会使用负载网关去代理转发请求给实际的后端服务，这时候请求日志还会包括以下数据：
upstream_host : 代理转发的 host upstream_addr : 代理转发的 IP 地址 upstream_url : 代理转发给服务的 url upstream_status : 上游服务返回的 status proxy_time : 代理转发过程中的耗时 数据衍生 Link to heading 客户端 IP 地址可以衍生出以下数据：</description></item><item><title>Elasticsearch 自定义打分 Function score query</title><link>https://rifewang.github.io/posts/elasticsearch/es-function-score-query/</link><pubDate>Mon, 02 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-function-score-query/</guid><description>Elasticsearch 自定义打分 Function score query Link to heading Elasticsearch 会为 query 的每个文档计算一个相关度得分 score ，并默认按照 score 从高到低的顺序返回搜索结果。 在很多场景下，我们不仅需要搜索到匹配的结果，还需要能够按照某种方式对搜索结果重新打分排序。例如：
搜索具有某个关键词的文档，同时考虑到文档的时效性进行综合排序。 搜索某个旅游景点附近的酒店，同时根据距离远近和价格等因素综合排序。 搜索标题包含 elasticsearch 的文章，同时根据浏览次数和点赞数进行综合排序。 Function score query 就可以让我们实现对最终 score 的自定义打分。
score 自定义打分过程 Link to heading 为了行文方便，本文把 ES 对 query 匹配的文档进行打分得到的 score 记为 query_score ，而最终搜索结果的 score 记为 result_score ，显然，一般情况下（也就是不使用自定义打分时），result_score 就是 query_score 。
那么当我们使用了自定义打分之后呢？最终结果的 score 即 result_score 的计算过程如下：
跟原来一样执行 query 并且得到原来的 query_score 。 执行设置的自定义打分函数，并为每个文档得到一个新的分数，本文记为 func_score 。 最终结果的分数 result_score 等于 query_score 与 func_score 按某种方式计算的结果（默认是相乘）。 例如，搜索标题包含 elasticsearch 的文档。</description></item><item><title>Logstash 入门</title><link>https://rifewang.github.io/posts/elasticsearch/logstash/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/logstash/</guid><description>Logstash 入门 Link to heading Logstash 是什么 Link to heading Logstash 就是一个开源的数据流工具，它会做三件事：
从数据源拉取数据 对数据进行过滤、转换等处理 将处理后的数据写入目标地 例如：
监听某个目录下的日志文件，读取文件内容，处理数据，写入 influxdb 。 从 kafka 中消费消息，处理数据，写入 elasticsearch 。 为什么要用 Logstash ？ Link to heading 方便省事。
假设你需要从 kafka 中消费数据，然后写入 elasticsearch ，如果自己编码，你得去对接 kafka 和 elasticsearch 的 API 吧，如果你用 Logstash ，这部分就不用自己去实现了，因为 Logstash 已经为你封装了对应的 plugin 插件，你只需要写一个配置文件形如：
input { kafka { # kafka consumer 配置 } } filter { # 数据处理配置 } output { elasticsearch { # elasticsearch 输出配置 } } 然后运行 logstash 就可以了。</description></item><item><title>又拍图片管家亿级图像之搜图系统的两代演进及底层原理</title><link>https://rifewang.github.io/posts/engineering/image-search-total/</link><pubDate>Thu, 04 Jun 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/engineering/image-search-total/</guid><description>又拍图片管家亿级图像之搜图系统的两代演进及底层原理 Link to heading 前言 Link to heading 又拍图片管家当前服务了千万级用户，管理了百亿级图片。当用户的图库变得越来越庞大时，业务上急切的需要一种方案能够快速定位图像，即直接输入图像，然后根据输入的图像内容来找到图库中的原图及相似图，而以图搜图服务就是为了解决这个问题。
本人于在职期间独立负责并实施了整个以图搜图系统从技术调研、到设计验证、以及最后工程实现的全过程。而整个以图搜图服务也是经历了两次的整体演进：从 2019 年初开始第一次技术调研，经历春节假期，2019 年 3、4 月份第一代系统整体上线；2020 年初着手升级方案调研，经历春节及疫情，2020 年 4 月份开始第二代系统的整体升级。
本文将会简述两代搜图系统背后的技术选型及基本原理。
基础概要 Link to heading 图像是什么？ Link to heading 与图像打交道，我们必须要先知道：图像是什么？
答案：像素点的集合。
比如：
左图红色圈中的部分其实就是右图中一系列的像素点。
再举例：
假设上图红色圈的部分是一幅图像，其中每一个独立的小方格就是一个像素点（简称像素），像素是最基本的信息单元，而这幅图像的大小就是 11 x 11 px 。
图像的数学表示 Link to heading 每个图像都可以很自然的用矩阵来表示，每个像素点对应的就是矩阵中的一个元素。
二值图像 Link to heading 二值图像的像素点只有黑白两种情况，因此每个像素点可以由 0 和 1 来表示。
比如一张 4 * 4 二值图像：
0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 RGB 图像 Link to heading 红（Red）、绿（Green）、蓝（Blue）作为三原色可以调和成任意的颜色，对于 RGB 图像，每个像素点包含 RGB 共三个通道的基本信息，类似的，如果每个通道用 8 bit 表示即 256 级灰度，那么一个像素点可以表示为：</description></item><item><title>以图搜图系统工程实践</title><link>https://rifewang.github.io/posts/engineering/image-search-system2/</link><pubDate>Sat, 11 Apr 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/engineering/image-search-system2/</guid><description>以图搜图系统工程实践 Link to heading 之前写过一篇概述: 以图搜图系统概述 。
以图搜图系统需要解决的主要问题是：
提取图像特征向量（用特征向量去表示一幅图像） 特征向量的相似度计算（寻找内容相似的图像） 对应的工程实践，具体为：
卷积神经网络 CNN 提取图像特征 向量搜索引擎 Milvus CNN Link to heading 使用卷积神经网路 CNN 去提取图像特征是一种主流的方案，具体的模型则可以使用 VGG16 ，技术实现上则使用 Keras + TensorFlow ，参考 Keras 官方示例：
from keras.applications.vgg16 import VGG16 from keras.preprocessing import image from keras.applications.vgg16 import preprocess_input import numpy as np model = VGG16(weights=&amp;#39;imagenet&amp;#39;, include_top=False) img_path = &amp;#39;elephant.jpg&amp;#39; img = image.load_img(img_path, target_size=(224, 224)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) x = preprocess_input(x) features = model.</description></item><item><title>以图搜图系统概述</title><link>https://rifewang.github.io/posts/engineering/image-search-system/</link><pubDate>Tue, 31 Mar 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/engineering/image-search-system/</guid><description>以图搜图系统概述 Link to heading 以图搜图指的是根据图像内容搜索出相似内容的图像。
构建一个以图搜图系统需要解决两个最关键的问题：首先，提取图像特征；其次，特征数据搜索引擎，即特征数据构建成数据库并提供相似性搜索的功能。
图像特征表示 Link to heading 介绍三种方式。
图像哈希 Link to heading 图像通过一系列的变换和处理最终得到的一组哈希值称之为图像的哈希值，而中间的变换和处理过程则称之为哈希算法。
图像的哈希值是对这张图像的整体抽象表示。
比如 Average Hash 算法的计算过程： Reduce size : 将原图压缩到 8 x 8 即 64 像素大小，忽略细节。 Reduce color : 灰度处理得到 64 级灰度图像。 Average the colors : 计算 64 级灰度均值。 Compute the bits : 二值化处理，将每个像素与上一步均值比较并分别记为 0 或者 1 。 Construct the hash : 根据上一步结果矩阵构成一个 64 bit 整数，比如按照从左到右、从上到下的顺序。最后得到的就是图像的均值哈希值。 参考：http://www.hackerfactor.com/blog/?/archives/432-Looks-Like-It.html
图像哈希算法有很多种，包含但不限于:
AverageHash : 也叫 Different Hash PHash : Perceptual Hash MarrHildrethHash : Marr-Hildreth Operator Based Hash RadialVarianceHash : Image hash based on Radon transform BlockMeanHash : Image hash based on block mean ColorMomentHash : Image hash based on color moments 我们最常见可能就是 PHash 。</description></item><item><title>GitHub Actions 指南</title><link>https://rifewang.github.io/posts/uncate/github-actions/</link><pubDate>Mon, 23 Dec 2019 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/uncate/github-actions/</guid><description>GitHub Actions 指南 Link to heading GitHub Actions 使你可以直接在你的 GitHub 库中创建自定义的工作流，工作流指的就是自动化的流程，比如构建、测试、打包、发布、部署等等，也就是说你可以直接进行 CI（持续集成）和 CD （持续部署）。
基本概念 Link to heading workflow : 一个 workflow 工作流就是一个完整的过程，每个 workflow 包含一组 jobs 任务。 job : jobs 任务包含一个或多个 job ，每个 job 包含一系列的 steps 步骤。 step : 每个 step 步骤可以执行指令或者使用一个 action 动作。 action : 每个 action 动作就是一个通用的基本单元。 配置 workflow Link to heading workflow 必须存储在你的项目库根路径下的 .github/workflows 目录中，每一个 workflow 对应一个具体的 .yml 文件（或者 .yaml）。
workflow 示例：
name: Greet Everyone # This workflow is triggered on pushes to the repository.</description></item><item><title>给你的库加上酷炫的小徽章</title><link>https://rifewang.github.io/posts/uncate/ava-codecov-travis/</link><pubDate>Sat, 21 Dec 2019 13:36:00 +0800</pubDate><guid>https://rifewang.github.io/posts/uncate/ava-codecov-travis/</guid><description>给库加上酷炫的小徽章 &amp;amp; ava、codecov、travis 示例 Link to heading GitHub 很多开源库都会有几个酷炫的小徽章，比如：
这些是怎么加上去的呢？
Shields.io Link to heading 首先这些徽章可以直接去 shields.io 网站自动生成。
比如：
就是 version 这一类里的一种图标，选择 npm 一栏填入包名，然后复制成 Markdown 内容，就会得到诸如：
![npm (tag)](https://img.shields.io/npm/v/io-memcached/latest) 直接粘贴在 .md 文件中就可以使用了，最后展现的就是这个图标。
当然还有其他很多徽章都任由你挑选，不过某些徽章是需要额外进行一些配置，比如这里的 (自动构建通过) 和 (测试覆盖率)。
AVA Link to heading 谈到测试覆盖率必须先有单元测试，本文使用 ava 作为示例，ava 是一个 js 测试库，强烈推荐你使用它。
1、安装
npm init ava 2、使用示例
编写 test.js 文件：
import test from &amp;#39;ava&amp;#39; import Memcached from &amp;#39;../lib/memcached&amp;#39;; test.before(t =&amp;gt; { const memcached = new Memcached([&amp;#39;127.0.0.1:11211&amp;#39;], { pool: { max: 2, min: 0 }, timeout: 5000 }); t.</description></item><item><title>使用 Makefile 构建指令集</title><link>https://rifewang.github.io/posts/uncate/makefile/</link><pubDate>Sun, 15 Dec 2019 13:39:47 +0800</pubDate><guid>https://rifewang.github.io/posts/uncate/makefile/</guid><description>使用 Makefile 构建指令集 Link to heading make 是一个历史悠久的构建工具，通过配置 Makefile 文件就可以很方便的使用你自己自定义的各种指令集，且与具体的编程语言无关。 例如配置如下的 Makefile :
run dev: NODE_ENV=development nodemon server.js 这样当你在命令行执行 make run dev 时其实就会执行 NODE_ENV=development nodemon server.js 指令。
使用 Makefile 构建指令集可以很大的提升工作效率。
Makefile 基本语法 Link to heading &amp;lt;target&amp;gt;: &amp;lt;prerequisites&amp;gt; &amp;lt;commands&amp;gt; target 其实就是执行的目标，prerequisites 是执行这条指令的前置条件，commands 就是具体的指令内容。
示例：
build: clean go build -o myapp main.go clean: rm -rf myapp 这里的 build 有一个前置条件 clean ，意思就是当你执行 make build 时，会先执行 clean 的指令内容 rm -rf myapp ，然后再执行 build 的内容 go build -o myapp main.</description></item><item><title>实现 memcached 客户端：TCP、连接池、一致性哈希、自定义协议</title><link>https://rifewang.github.io/posts/uncate/create-memcached-client/</link><pubDate>Mon, 09 Dec 2019 13:41:38 +0800</pubDate><guid>https://rifewang.github.io/posts/uncate/create-memcached-client/</guid><description>实现 memcached 客户端：TCP、连接池、一致性哈希、自定义协议。 Link to heading 废话不多说，文本将带你实现一个简单的 memcached 客户端。
集群：一致性哈希 Link to heading memcached 本身并不支持集群，为了使用集群，我们可以自己在客户端实现路由分发，将相同的 key 路由到同一台 memcached 上去即可。 路由算法有很多，这里我们使用一致性哈希算法。
一致性哈希算法的原理：
一致性哈希算法已经有开源库 hashring 实现，基本用法：
const HashRing = require(&amp;#39;hashring&amp;#39;); // 输入集群地址构造 hash ring const ring = new HashRing([&amp;#39;127.0.0.1:11211&amp;#39;, &amp;#39;127.0.0.2:11211&amp;#39;]); // 输入 key 获取指定节点 const host = ring.get(key); TCP 编程 Link to heading 包括 memcached 在内的许多系统对外都是通过 TCP 通信。在 Node.js 中建立一个 TCP 连接并进行数据的收发很简单：
const net = require(&amp;#39;net&amp;#39;); const socket = new net.Socket(); socket.</description></item></channel></rss>