<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>AI 声音：数字音频、语音识别、TTS 简介与使用示例 - 凌虚 Blog</title><meta name=Description content="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><meta property="og:url" content="https://rifewang.github.io/audio-asr-tts/">
<meta property="og:site_name" content="凌虚 Blog"><meta property="og:title" content="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><meta property="og:description" content="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-28T12:02:09+08:00"><meta property="article:modified_time" content="2024-11-28T15:52:24+08:00"><meta property="article:tag" content="AI"><meta property="og:image" content="https://rifewang.github.io/images/avatar.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://rifewang.github.io/images/avatar.png"><meta name=twitter:title content="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><meta name=twitter:description content="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><meta name=application-name content="凌虚的博客"><meta name=apple-mobile-web-app-title content="凌虚的博客"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel=canonical href=https://rifewang.github.io/audio-asr-tts/><link rel=prev href=https://rifewang.github.io/web-voice-chat-llm/><link rel=next href=https://rifewang.github.io/flannel-calico/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"AI 声音：数字音频、语音识别、TTS 简介与使用示例","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/rifewang.github.io\/audio-asr-tts\/"},"image":["https:\/\/rifewang.github.io\/images\/avatar.png"],"genre":"posts","keywords":"AI","wordcount":1639,"url":"https:\/\/rifewang.github.io\/audio-asr-tts\/","datePublished":"2024-11-28T12:02:09+08:00","dateModified":"2024-11-28T15:52:24+08:00","license":"Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)","publisher":{"@type":"Organization","name":"凌虚","logo":"https:\/\/rifewang.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"凌虚"},"description":"AI 声音：数字音频、语音识别、TTS 简介与使用示例"}</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-VRMQFEVL7J"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VRMQFEVL7J")</script><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"light"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"light"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="凌虚 Blog">凌虚的博客</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/about>作者 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="凌虚 Blog">凌虚的博客</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/about title>作者</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">AI 声音：数字音频、语音识别、TTS 简介与使用示例</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>凌虚</a></span>&nbsp;<span class=post-category>included in <a href=/categories/ai/><i class="far fa-folder fa-fw" aria-hidden=true></i>AI</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2024-11-28>2024-11-28</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;1639 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;4 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#数字音频>数字音频</a></li><li><a href=#asr-语音识别>ASR 语音识别</a><ul><li><ul><li><a href=#传统方法>传统方法</a></li><li><a href=#深度学习>深度学习</a></li></ul></li></ul></li><li><a href=#tts-文本转语言>TTS 文本转语言</a><ul><li><ul><li><a href=#声音克隆>声音克隆</a></li></ul></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></div><div class=content id=content><p>在现代 AI 技术的推动下，声音处理领域取得了巨大进展。从语音识别（<code>ASR</code>）到文本转语音（<code>TTS</code>），再到个性化声音克隆，这些技术已经深入到我们的日常生活中：语音助手、自动字幕生成、语音导航等应用无处不在。</p><h2 id=数字音频>数字音频</h2><p>音频是声音的“数字化”。声音本质上是空气中振动的波，这些波的振动被麦克风捕捉后转化为电信号。接着，这些信号会通过采样和量化存储为数字数据。</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://raw.githubusercontent.com/RifeWang/images/master/ai/AI-analog-to-audio.drawio.png data-srcset="https://raw.githubusercontent.com/RifeWang/images/master/ai/AI-analog-to-audio.drawio.png, https://raw.githubusercontent.com/RifeWang/images/master/ai/AI-analog-to-audio.drawio.png 1.5x, https://raw.githubusercontent.com/RifeWang/images/master/ai/AI-analog-to-audio.drawio.png 2x" data-sizes=auto alt=https://raw.githubusercontent.com/RifeWang/images/master/ai/AI-analog-to-audio.drawio.png title=https://raw.githubusercontent.com/RifeWang/images/master/ai/AI-analog-to-audio.drawio.png></p><p>如上图所示。声波最开始是一个连续的模拟信号，然后经过特定频率的采样得到采样点（比如采样频率 48kHz 就是将每秒切割为 48k 个采样点），再通过量化处理得到二进制数据（如果量化位数是 16 位，则表示每个采样点存储为 16 bit 即 2 个字节），最后将元数据（如采样率、量化位数、声道数量等）和采样点二进制数据组合起来就得到了音频文件（比如 WAV 或 MP3）。</p><h2 id=asr-语音识别>ASR 语音识别</h2><p>语音识别（<code>Automatic Speech Recognition</code>，<code>ASR</code>）是将语言转化为文字的技术。</p><h4 id=传统方法>传统方法</h4><p>早期的 <code>ASR</code> 系统主要依赖基于统计的模型，如：</p><ul><li>声学模型（Acoustic Model）：将音频信号转换为声学特征，如 MFCC（梅尔频率倒谱系数）。</li><li>语言模型（Language Model）：使用统计方法预测文字序列的概率。</li><li>解码器（Decoder）：结合声学和语言模型，将声学特征映射到最可能的文字序列。</li></ul><p>这些方法需要大量手工设计的特征和规则，性能受限于数据量和语言模型的复杂度。</p><h4 id=深度学习>深度学习</h4><p>现代 <code>ASR</code> 系统主要基于深度学习，使用端到端（End-to-End）方法，直接从音频输入到文本输出。</p><p>如果将 AI 模型看作一个黑盒，那么训练过程就是输入 &lt;音频, 文本> 数据对，让模型自动学习输入和输出之间的映射关系。经过训练后，模型便可以对新的音频进行推理，生成对应文本。</p><p>这种描述是一个高度抽象的视角，背后实际上是一个复杂的过程，比如 <code>OpenAI Whisper</code>：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://raw.githubusercontent.com/RifeWang/images/master/ai/openai-whisper.png data-srcset="https://raw.githubusercontent.com/RifeWang/images/master/ai/openai-whisper.png, https://raw.githubusercontent.com/RifeWang/images/master/ai/openai-whisper.png 1.5x, https://raw.githubusercontent.com/RifeWang/images/master/ai/openai-whisper.png 2x" data-sizes=auto alt=https://raw.githubusercontent.com/RifeWang/images/master/ai/openai-whisper.png title=https://raw.githubusercontent.com/RifeWang/images/master/ai/openai-whisper.png></p><p>实践证明，基于深度学习方法训练出来的模型具有更好的鲁棒性、准确性和泛化能力。</p><p><code>OpenAI Whisper</code> 使用示例：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>whisper</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型，默认存储位置 ~/.cache/whisper，可以设置 download_root 改变路径</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>whisper</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&#34;base&#34;</span><span class=p>,</span> <span class=n>download_root</span><span class=o>=</span><span class=s2>&#34;root_dir&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 将音频转换为文本</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>transcribe</span><span class=p>(</span><span class=s2>&#34;audio.mp3&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>你也可以使用 <code>whisper.cpp</code>，一个使用 C/C++ 编写的 <code>OpenAI Whisper</code> 的高性能版本。</p><h2 id=tts-文本转语言>TTS 文本转语言</h2><p>文本转语音（<code>Text-to-Speech</code>，<code>TTS</code>）技术则是将输入文本转化为自然流畅的语音。</p><p>从某种抽象的角度来看，<code>TTS</code>（文本转语音）可以被视为语音识别（<code>ASR</code>）的“反过程”，两者都涉及将一种形式的数据（音频或文本）映射到另一种形式，并且现代都采用深度学习模型，通常基于 <code>Transformer</code> 或类似架构，但在某些技术实现（比如中间表示、损失函数、特征表示、目标优化等）和复杂度上并非完全对称。</p><p><code>TTS</code> 示例如下（使用的是 <code>HuggingFace</code> 上的 <code>OuteAI/OuteTTS-0.2-500M</code> 模型）：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>outetts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_config</span> <span class=o>=</span> <span class=n>outetts</span><span class=o>.</span><span class=n>HFModelConfig_v1</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_path</span><span class=o>=</span><span class=s2>&#34;OuteAI/OuteTTS-0.2-500M&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>language</span><span class=o>=</span><span class=s2>&#34;en&#34;</span><span class=p>,</span>  <span class=c1># Supported languages in v0.2: en, zh, ja, ko</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>interface</span> <span class=o>=</span> <span class=n>outetts</span><span class=o>.</span><span class=n>InterfaceHF</span><span class=p>(</span><span class=n>model_version</span><span class=o>=</span><span class=s2>&#34;0.2&#34;</span><span class=p>,</span> <span class=n>cfg</span><span class=o>=</span><span class=n>model_config</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Optional: Load speaker from default presets</span>
</span></span><span class=line><span class=cl><span class=n>interface</span><span class=o>.</span><span class=n>print_default_speakers</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>speaker</span> <span class=o>=</span> <span class=n>interface</span><span class=o>.</span><span class=n>load_default_speaker</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;male_1&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>interface</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=o>=</span><span class=s2>&#34;&#34;&#34;Speech synthesis is the artificial production of human speech.
</span></span></span><span class=line><span class=cl><span class=s2>    A computer system used for this purpose is called a speech synthesizer,
</span></span></span><span class=line><span class=cl><span class=s2>    and it can be implemented in software or hardware products.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># Lower temperature values may result in a more stable tone,</span>
</span></span><span class=line><span class=cl>    <span class=c1># while higher values can introduce varied and expressive speech</span>
</span></span><span class=line><span class=cl>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>repetition_penalty</span><span class=o>=</span><span class=mf>1.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_length</span><span class=o>=</span><span class=mi>4096</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>speaker</span><span class=o>=</span><span class=n>speaker</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&#34;output.wav&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=声音克隆>声音克隆</h4><p>每个人的声音都有独特的特性，比如音调高低、响度、停顿、语气等等，声音克隆就是分析并提取一个人的声音特征，将这些特征参数化（通常表示为高维向量）。特征提取本身没有多大实际用途，为了让这些特征发挥作用，声音克隆通常与 <code>TTS</code>（文本转语音）技术结合，融合克隆的声音特征，将文本生成为与克隆声音相似的语音。</p><p>不少 <code>TTS</code> 模型也会直接支持声音克隆的功能，如何调用则取决于具体的模型。例如上例中的 <code>OuteAI/OuteTTS-0.2-500M</code> 模型可以输入一段音频创建具有该音频特征的 speaker：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Optional: Create a speaker profile (use a 10-15 second audio clip)</span>
</span></span><span class=line><span class=cl><span class=n>speaker</span> <span class=o>=</span> <span class=n>interface</span><span class=o>.</span><span class=n>create_speaker</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>audio_path</span><span class=o>=</span><span class=s2>&#34;path/to/audio/file&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>transcript</span><span class=o>=</span><span class=s2>&#34;Transcription of the audio file.&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=总结>总结</h2><p>语音技术作为 <code>AI</code> 应用中的重要分支，正在改变人机交互的方式。从基础的数字音频处理到 <code>ASR</code> 和 <code>TTS</code> 技术的成熟，再到声音克隆赋予 <code>AI</code> 个性化表达能力，这些技术不仅满足了自动化需求，还为虚拟助手、娱乐、医疗、教育等领域带来了创新可能性。希望本文的介绍能为你打开探索 AI 声音领域的大门！</p><hr><p>(我是凌虚，关注我，无广告，专注技术，不煽动情绪，欢迎与我交流)</p><hr><p>参考资料：</p><ul><li><em><a href=https://github.com/openai/whisper target=_blank rel="noopener noreffer">https://github.com/openai/whisper</a></em></li><li><em><a href=https://huggingface.co/OuteAI/OuteTTS-0.2-500M target=_blank rel="noopener noreffer">https://huggingface.co/OuteAI/OuteTTS-0.2-500M</a></em></li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2024-11-28</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://rifewang.github.io/audio-asr-tts/ data-title="AI 声音：数字音频、语音识别、TTS 简介与使用示例" data-hashtags=AI><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://rifewang.github.io/audio-asr-tts/ data-hashtag=AI><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://rifewang.github.io/audio-asr-tts/ data-title="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://rifewang.github.io/audio-asr-tts/ data-title="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><i data-svg-src=/lib/simple-icons/icons/line.min.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://rifewang.github.io/audio-asr-tts/ data-title="AI 声音：数字音频、语音识别、TTS 简介与使用示例"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/ai/>AI</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/web-voice-chat-llm/ class=prev rel=prev title="Web 端语音对话 AI 示例：使用 Whisper 和 llama.cpp 构建语音聊天机器人"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Web 端语音对话 AI 示例：使用 Whisper 和 llama.cpp 构建语音聊天机器人</a>
<a href=/flannel-calico/ class=next rel=next title="Kubernetes 集群网络：Flannel 与 Calico 的区别">Kubernetes 集群网络：Flannel 与 Calico 的区别<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2017 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>凌虚</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=/lib/katex/katex.min.css><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/contrib/auto-render.min.js></script><script type=text/javascript src=/lib/katex/contrib/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:50,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>