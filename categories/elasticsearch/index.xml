<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Elasticsearch on 凌虚 Blog</title><link>https://rifewang.github.io/categories/elasticsearch/</link><description>Recent content in Elasticsearch on 凌虚 Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 15 Apr 2022 00:00:00 +0800</lastBuildDate><atom:link href="https://rifewang.github.io/categories/elasticsearch/index.xml" rel="self" type="application/rss+xml"/><item><title>Elasticsearch 向量搜索</title><link>https://rifewang.github.io/posts/elasticsearch/es-vector-search/</link><pubDate>Fri, 15 Apr 2022 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-vector-search/</guid><description>Elasticsearch 向量搜索 Link to heading 本文将会介绍 Elasticsearch 向量搜索的两种方式。
向量搜索 Link to heading 提到向量搜索，我想你一定想知道：
向量搜索是什么？ 向量搜索的应用场景有哪些？ 向量搜索与全文搜索有何不同？ ES 的全文搜索简而言之就是将文本进行分词，然后基于词通过 BM25 算法计算相关性得分，从而找到与搜索语句相似的文本，其本质上是一种 term-based（基于词）的搜索。
全文搜索的实际使用已经非常广泛，核心技术也非常成熟。但是，除了文本内容之外，现实生活中还有非常多其它的数据形式，例如：图片、音频、视频等等，我们能不能也对这些数据进行搜索呢？
答案是 Yes !
随着机器学习和人工智能等技术的发展，万物皆可 Embedding。换句话说就是，我们可以对文本、图片、音频、视频等等一切数据通过 Embedding 相关技术将其转换成特征向量，而一旦向量有了，向量搜索的需求随之也越发强烈，向量搜索的应用场景也变得一望无际、充满想象力。
ES 向量搜索说明 Link to heading ES 向量搜索目前有两种方式:
script_score _knn_search script_score 精确搜索 Link to heading ES 7.6 版本对新增的字段类型 dense_vector 确认了稳定性保证，这个字段类型就是用来表示向量数据的。
数据建模示例：
PUT my-index { &amp;#34;mappings&amp;#34;: { &amp;#34;properties&amp;#34;: { &amp;#34;my_vector&amp;#34;: { &amp;#34;type&amp;#34;: &amp;#34;dense_vector&amp;#34;, &amp;#34;dims&amp;#34;: 128 }, &amp;#34;my_text&amp;#34; : { &amp;#34;type&amp;#34; : &amp;#34;keyword&amp;#34; } } } } 如上图所示，我们在索引中建立了一个 dims 维度为 128 的向量数据字段。</description></item><item><title>Elasticsearch 分布式搜索的运行机制</title><link>https://rifewang.github.io/posts/elasticsearch/es-distribute-search-steps/</link><pubDate>Tue, 17 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-distribute-search-steps/</guid><description>Elasticsearch 分布式搜索的运行机制 Link to heading ES 有两种 search_type 即搜索类型：
query_then_fetch （默认） dfs_query_then_fetch query_then_fetch Link to heading 用户发起搜索，请求到集群中的某个节点。 query 会被发送到所有相关的 shard 分片上。 每个 shard 分片独立执行 query 搜索文档并进行排序分页等，打分时使用的是分片本身的 Local Term/Document 频率。 分片的 query 结果（只有元数据，例如 _id 和 _score）返回给请求节点。 请求节点对所有分片的 query 结果进行汇总，然后根据打分排序和分页，最后选择出搜索结果文档（也只有元数据）。 根据元数据去对应的 shard 分片拉取存储在磁盘上的文档的详细数据。 得到详细的文档数据，组成搜索结果，将结果返回给用户。 缺点：由于每个分片独立使用自身的而不是全局的 Term/Document 频率进行相关度打分，当数据分布不均匀时可能会造成打分偏差，从而影响最终搜索结果的相关性。
dfs_query_then_fetch Link to heading dfs_query_then_fetch 与 query_then_fetch 的运行机制非常类似，但是有两点不同。
用户发起搜索，请求到集群中的某个节点。 预查询每个分片，得到全局的 Global Term/Document 频率。 query 会被发送到所有相关的 shard 分片上。 每个 shard 分片独立执行 query 搜索文档并进行排序分页等，打分时使用的是分片本身的 Global Term/Document 频率。 分片的 query 结果（只有元数据，例如 _id 和 _score）返回给请求节点。 请求节点对所有分片的 query 结果进行汇总，然后根据打分排序和分页，最后选择出搜索结果文档（也只有元数据）。 根据元数据去对应的 shard 分片拉取存储在磁盘上的文档的详细数据。 得到详细的文档数据，组成搜索结果，将结果返回给用户。 缺点：太耗费资源，一般还是不建议使用。</description></item><item><title>Elasticsearch Search Template</title><link>https://rifewang.github.io/posts/elasticsearch/es-search-template/</link><pubDate>Mon, 16 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-search-template/</guid><description>Elasticsearch Search Template Link to heading 所谓 search template 搜索模板其实就是：
预先定义好查询语句 DSL 的结构并预留参数 搜索的时再传入参数值 渲染出完整的 DSL ，最后进行搜索 使用搜索模板可以将 DSL 从应用程序中解耦出来，并且可以更加灵活的更改查询语句。
例如：
GET _search/template { &amp;#34;source&amp;#34; : { &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34; : { &amp;#34;{{my_field}}&amp;#34; : &amp;#34;{{my_value}}&amp;#34; } } }, &amp;#34;params&amp;#34; : { &amp;#34;my_field&amp;#34; : &amp;#34;message&amp;#34;, &amp;#34;my_value&amp;#34; : &amp;#34;foo&amp;#34; } } 构造出来的 DSL 就是：
{ &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34;: { &amp;#34;message&amp;#34;: &amp;#34;foo&amp;#34; } } } 在模板中通过 {{ }} 的方式预留参数，然后查询时再指定对应的参数值，最后填充成具体的查询语句进行搜索。
搜索模板 API Link to heading 为了实现搜索模板和查询分离，我们首先需要单独保存和管理搜索模板。</description></item><item><title>构造请求日志分析系统</title><link>https://rifewang.github.io/posts/elasticsearch/log-analyzer-system/</link><pubDate>Sat, 07 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/log-analyzer-system/</guid><description>构造请求日志分析系统 Link to heading 请求日志记录哪些数据 Link to heading time_local : 请求的时间 remote_addr : 客户端的 IP 地址 request_method : 请求方法 request_schema : 请求协议，常见的 http 和 https request_host : 请求的域名 request_path : 请求的 path 路径 request_query : 请求的 query 参数 request_size : 请求的大小 referer : 请求来源地址，假设你在 a.com 网站下贴了 b.com 的链接，那么当用户从 a.com 点击访问 b.com 的时候，referer 记录的就是 a.com ，这个是浏览器的行为 user_agent : 客户端浏览器相关信息 status : 请求的响应状态 request_time : 请求的耗时 bytes_sent : 响应的大小 很多时候我们会使用负载网关去代理转发请求给实际的后端服务，这时候请求日志还会包括以下数据：
upstream_host : 代理转发的 host upstream_addr : 代理转发的 IP 地址 upstream_url : 代理转发给服务的 url upstream_status : 上游服务返回的 status proxy_time : 代理转发过程中的耗时 数据衍生 Link to heading 客户端 IP 地址可以衍生出以下数据：</description></item><item><title>Elasticsearch 自定义打分 Function score query</title><link>https://rifewang.github.io/posts/elasticsearch/es-function-score-query/</link><pubDate>Mon, 02 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/es-function-score-query/</guid><description>Elasticsearch 自定义打分 Function score query Link to heading Elasticsearch 会为 query 的每个文档计算一个相关度得分 score ，并默认按照 score 从高到低的顺序返回搜索结果。 在很多场景下，我们不仅需要搜索到匹配的结果，还需要能够按照某种方式对搜索结果重新打分排序。例如：
搜索具有某个关键词的文档，同时考虑到文档的时效性进行综合排序。 搜索某个旅游景点附近的酒店，同时根据距离远近和价格等因素综合排序。 搜索标题包含 elasticsearch 的文章，同时根据浏览次数和点赞数进行综合排序。 Function score query 就可以让我们实现对最终 score 的自定义打分。
score 自定义打分过程 Link to heading 为了行文方便，本文把 ES 对 query 匹配的文档进行打分得到的 score 记为 query_score ，而最终搜索结果的 score 记为 result_score ，显然，一般情况下（也就是不使用自定义打分时），result_score 就是 query_score 。
那么当我们使用了自定义打分之后呢？最终结果的 score 即 result_score 的计算过程如下：
跟原来一样执行 query 并且得到原来的 query_score 。 执行设置的自定义打分函数，并为每个文档得到一个新的分数，本文记为 func_score 。 最终结果的分数 result_score 等于 query_score 与 func_score 按某种方式计算的结果（默认是相乘）。 例如，搜索标题包含 elasticsearch 的文档。</description></item><item><title>Logstash 入门</title><link>https://rifewang.github.io/posts/elasticsearch/logstash/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0800</pubDate><guid>https://rifewang.github.io/posts/elasticsearch/logstash/</guid><description>Logstash 入门 Link to heading Logstash 是什么 Link to heading Logstash 就是一个开源的数据流工具，它会做三件事：
从数据源拉取数据 对数据进行过滤、转换等处理 将处理后的数据写入目标地 例如：
监听某个目录下的日志文件，读取文件内容，处理数据，写入 influxdb 。 从 kafka 中消费消息，处理数据，写入 elasticsearch 。 为什么要用 Logstash ？ Link to heading 方便省事。
假设你需要从 kafka 中消费数据，然后写入 elasticsearch ，如果自己编码，你得去对接 kafka 和 elasticsearch 的 API 吧，如果你用 Logstash ，这部分就不用自己去实现了，因为 Logstash 已经为你封装了对应的 plugin 插件，你只需要写一个配置文件形如：
input { kafka { # kafka consumer 配置 } } filter { # 数据处理配置 } output { elasticsearch { # elasticsearch 输出配置 } } 然后运行 logstash 就可以了。</description></item></channel></rss>